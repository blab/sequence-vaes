{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1b8a8c-ae6c-45da-b640-06bb80568e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to sequence_vaes directory\n",
    "# abspath = \"/content/drive/MyDrive/bedford_lab/code/seq_vaes\"\n",
    "abspath = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4965df-6a82-42e1-8071-f1263a21b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import json\n",
    "from treetime.utils import datetime_from_numeric\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# path to sequence_vaes directory and pip install\n",
    "# %cd \"/content/drive/MyDrive/bedford_lab/code/seq_vaes\"\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b0f6f0-688e-485c-aa27-fcab57091643",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(abspath)\n",
    "from models import DNADataset, ALPHABET, SEQ_LENGTH, LATENT_DIM, VAE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE as tsne\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import bedford_code.models_bedford as bedford\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af17e471-d36f-44a0-b0c9-25098fe9f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# \"data\" directory is generated as shown in README.md file\n",
    "dataset = DNADataset(f\"{abspath}/data/training_spike.fasta\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13083b0-562d-4198-89a8-e62db09570e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12714a1c-16f3-4bc7-b499-7f1229d95c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/averma2/miniforge3/envs/Moreta_env/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (non_linear_activation): Softplus(beta=1.0, threshold=20)\n",
       "  (encoder): Encoder(\n",
       "    (non_linear_activation): Softplus(beta=1.0, threshold=20)\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=19110, out_features=512, bias=True)\n",
       "      (1): Softplus(beta=1.0, threshold=20)\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): Softplus(beta=1.0, threshold=20)\n",
       "    )\n",
       "    (fc_mean): Linear(in_features=256, out_features=50, bias=True)\n",
       "    (fc_logvar): Linear(in_features=256, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (non_linear_activation): Softplus(beta=1.0, threshold=20)\n",
       "    (decode): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=256, bias=True)\n",
       "      (1): Softplus(beta=1.0, threshold=20)\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): Softplus(beta=1.0, threshold=20)\n",
       "      (4): Linear(in_features=512, out_features=19110, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(ALPHABET) * SEQ_LENGTH\n",
    "# input_dim = 29903 * 5\n",
    "# input_dim = 29903\n",
    "\n",
    "#STANDARD\n",
    "vae_model = VAE(input_dim=input_dim, latent_dim=50, non_linear_activation=nn.Softplus(beta=1.0)).to(DEVICE)\n",
    "vae_model.load_state_dict(torch.load(\"./model_saves/standard_VAE_model_BEST.pth\", weights_only=True, map_location=DEVICE))\n",
    "\n",
    "\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbe27fe-c1c8-49ac-aa85-1bd182bd8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection_dates\n",
      " [21, 54, 67, 86, 108, 140, 154, 187, 206, 220, 240, 257, 264, 275, 282, 288, 291, 308, 333, 345, 358, 369, 377, 386, 397, 408, 416, 426, 435, 461, 798, 1373, 2807, 4105, 5241, 6264, 6368]\n",
      "\n",
      "unique clusters\n",
      " ['19A' '21K (BA.1)' '21L (BA.2)' '21M (Omicron)' '22A (BA.4)' '22B (BA.5)'\n",
      " '22C (BA.2.12.1)' '22D (BA.2.75)' '22E (BQ.1)' '22F (XBB)'\n",
      " '23A (XBB.1.5)' '23B (XBB.1.16)' '23C (CH.1.1)' '23D (XBB.1.9)'\n",
      " '23E (XBB.2.3)' '23F (EG.5.1)' '23G (XBB.1.5.70)' '23H (HK.3)'\n",
      " '23I (BA.2.86)' '24A (JN.1)' '24D (XDV.1)' '24E (KP.3.1.1)' '24F (XEC)'\n",
      " '24G (KP.2.3)' '24H (LF.7)' '24I (MV.1)' '25A (LP.8.1)' '25B (NB.1.8.1)'\n",
      " '25C (XFG)']\n",
      "\n",
      "sanity check - len(new_vals), len(vals)\n",
      " 6368   6368\n",
      "['new_dataset', 'vals', 'metadata', 'clade_labels', 'collection_dates', 'indexes', 'pairs', 'get_parents_dict']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "dset = [\"training\", \"valid\", \"test\"]\n",
    "dset = dset[0]\n",
    "abspath = \"..\"\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "data_keys, data_dict = utils.get_data_dict(dset, abspath)\n",
    "print(data_keys)\n",
    "new_dataset = data_dict[\"new_dataset\"]\n",
    "vals = data_dict[\"vals\"]\n",
    "metadata = data_dict[\"metadata\"]\n",
    "clade_labels = data_dict[\"clade_labels\"]\n",
    "collection_dates = data_dict[\"collection_dates\"]\n",
    "indexes = data_dict[\"indexes\"]\n",
    "pairs = data_dict[\"pairs\"]\n",
    "get_parents_dict = data_dict[\"get_parents_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab88b5d4-598e-4e86-8237-d9ed268b7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3822, 5])\n"
     ]
    }
   ],
   "source": [
    "vae_model = vae_model.requires_grad_(False)\n",
    "\n",
    "X = torch.tensor(new_dataset)\n",
    "X = X.view(X.size(0), -1).to(DEVICE)\n",
    "X = utils.mask_gaps(X,zero_idx=4)\n",
    "\n",
    "Z_mean, _ = vae_model.encoder.forward(X)\n",
    "\n",
    "z = Z_mean[0,:]\n",
    "r_z = vae_model.decoder.forward(z[None,:])\n",
    "print(r_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fe057d7-ba5e-4178-a950-5d18298cf9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (non_linear_activation): Softplus(beta=1.0, threshold=20)\n",
      "  (decode): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=256, bias=True)\n",
      "    (1): Softplus(beta=1.0, threshold=20)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): Softplus(beta=1.0, threshold=20)\n",
      "    (4): Linear(in_features=512, out_features=19110, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vae_model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8346b9e7-3dae-4d60-84e6-f62d31f64004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19110, 50])\n"
     ]
    }
   ],
   "source": [
    "grads = torch.autograd.functional.jacobian(vae_model.decoder.decode, z)\n",
    "print(grads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "753df4b1-6550-4bfc-9dc1-0c1c8df0eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torch.matmul(grads.T,grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6ecbecd-674c-4ff3-a412-061a05ccd048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8120e+01,  4.6728e+00,  6.8707e+02,  ..., -5.6763e+00,\n",
      "          1.0328e+01,  1.1984e+01],\n",
      "        [ 4.6728e+00,  2.8615e+00,  1.0975e+02,  ..., -1.9634e-01,\n",
      "          4.9572e+00,  1.9510e-01],\n",
      "        [ 6.8707e+02,  1.0975e+02,  1.7877e+04,  ..., -1.6073e+02,\n",
      "          1.8618e+02,  3.6894e+02],\n",
      "        ...,\n",
      "        [-5.6763e+00, -1.9634e-01, -1.6073e+02,  ...,  2.2123e+00,\n",
      "          5.6787e-01, -5.2093e+00],\n",
      "        [ 1.0328e+01,  4.9572e+00,  1.8618e+02,  ...,  5.6787e-01,\n",
      "          1.8152e+01, -6.7884e+00],\n",
      "        [ 1.1984e+01,  1.9510e-01,  3.6894e+02,  ..., -5.2093e+00,\n",
      "         -6.7884e+00,  1.6493e+01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab996e25-f3f6-4621-9085-639b772a8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(metric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63f591f9-5f7e-4c6b-8b4b-6ef22b071177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.0744, device='cuda:0')\n",
      "tensor(-8.0744, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n1 = 10\n",
    "n2 = 5\n",
    "\n",
    "print(metric[n1,n2])\n",
    "print(metric[n2,n1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d98b77c-6760-4ebe-8ca3-d9433497127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.all(torch.real(torch.linalg.eigvals(metric)) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128e14f-3937-4aba-bcb9-e92edfdc5135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
