{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bcf3c4-4580-496e-9850-2e6efa68b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import json\n",
    "from treetime.utils import datetime_from_numeric\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# path to sequence_vaes directory and pip install\n",
    "# %cd \"/content/drive/MyDrive/bedford_lab/code/seq_vaes\"\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48a0cfc-12c9-476d-8292-a985c569045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from models import DNADataset, ALPHABET, SEQ_LENGTH, LATENT_DIM, VAE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE as tsne\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import bedford_code.models_bedford as bedford\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2b9ce5-d904-421d-8400-e030832925e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "abspath = \"..\"\n",
    "# \"data\" directory is generated as shown in README.md file\n",
    "dataset = DNADataset(f\"{abspath}/data/training_spike.fasta\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc33bd17-85fa-44d9-8748-2a88d078d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af76ddc-ed2f-4e25-9b3f-0049397081d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/averma2/miniforge3/envs/Moreta_env/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (non_linear_activation): ReLU()\n",
       "  (encoder): Encoder(\n",
       "    (non_linear_activation): ReLU()\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=19110, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (fc_mean): Linear(in_features=256, out_features=50, bias=True)\n",
       "    (fc_logvar): Linear(in_features=256, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (non_linear_activation): ReLU()\n",
       "    (decode): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=19110, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(ALPHABET) * SEQ_LENGTH\n",
    "# input_dim = 29903 * 5\n",
    "# input_dim = 29903\n",
    "\n",
    "# BEDFORD\n",
    "# vae_model = bedford.VAE(input_dim=len(bedford.ALPHABET) * bedford.SEQ_LENGTH, latent_dim=bedford.LATENT_DIM).to(DEVICE)\n",
    "# vae_model.load_state_dict(torch.load(\"./bedford_code/results_bedford/BEST_vae_ce_anneal.pth\"))\n",
    "#STANDARD\n",
    "vae_model = VAE(input_dim=input_dim, latent_dim=50).to(DEVICE)\n",
    "vae_model.load_state_dict(torch.load(\"./model_saves/standard_VAE_model_BEST.pth\", weights_only=True, map_location=DEVICE))\n",
    "\n",
    "\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1c019d-783b-46de-bb5d-e1d83e630743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection_dates\n",
      " [21, 54, 67, 86, 108, 140, 154, 187, 206, 220, 240, 257, 264, 275, 282, 288, 291, 308, 333, 345, 358, 369, 377, 386, 397, 408, 416, 426, 435, 461, 798, 1373, 2807, 4105, 5241, 6264, 6368]\n",
      "\n",
      "unique clusters\n",
      " ['19A' '21K (BA.1)' '21L (BA.2)' '21M (Omicron)' '22A (BA.4)' '22B (BA.5)'\n",
      " '22C (BA.2.12.1)' '22D (BA.2.75)' '22E (BQ.1)' '22F (XBB)'\n",
      " '23A (XBB.1.5)' '23B (XBB.1.16)' '23C (CH.1.1)' '23D (XBB.1.9)'\n",
      " '23E (XBB.2.3)' '23F (EG.5.1)' '23G (XBB.1.5.70)' '23H (HK.3)'\n",
      " '23I (BA.2.86)' '24A (JN.1)' '24D (XDV.1)' '24E (KP.3.1.1)' '24F (XEC)'\n",
      " '24G (KP.2.3)' '24H (LF.7)' '24I (MV.1)' '25A (LP.8.1)' '25B (NB.1.8.1)'\n",
      " '25C (XFG)']\n",
      "\n",
      "sanity check - len(new_vals), len(vals)\n",
      " 6368   6368\n",
      "['new_dataset', 'vals', 'metadata', 'clade_labels', 'collection_dates', 'indexes', 'pairs', 'get_parents_dict']\n"
     ]
    }
   ],
   "source": [
    "dset = [\"training\", \"valid\", \"test\"]\n",
    "dset = dset[0]\n",
    "abspath = \"..\"\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "data_keys, data_dict = utils.get_data_dict(dset, abspath)\n",
    "print(data_keys)\n",
    "new_dataset = data_dict[\"new_dataset\"]\n",
    "vals = data_dict[\"vals\"]\n",
    "metadata = data_dict[\"metadata\"]\n",
    "clade_labels = data_dict[\"clade_labels\"]\n",
    "collection_dates = data_dict[\"collection_dates\"]\n",
    "indexes = data_dict[\"indexes\"]\n",
    "pairs = data_dict[\"pairs\"]\n",
    "get_parents_dict = data_dict[\"get_parents_dict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661f6e0-7ef7-49aa-9c0f-2fdec2176b1e",
   "metadata": {},
   "source": [
    "## Bayesian Influence functions (BIF)\n",
    "#### BIF estimates the influence function as follows: Given dataset $X=\\{x_n\\}_{n=1}^N$ where $x_n\\in \\mathbb{R}^D$, parameters $\\theta\\in\\Theta\\subseteq\\mathbb{R}^d$, and loss function $L(X, \\theta) = \\sum_n \\ell(x_n,\\theta)$, define observable $\\phi:\\Theta \\rightarrow \\mathbb{R}$ by $\\phi(\\theta) = \\ell(X_i,\\theta)$ for some given $i\\in [N]$. We can approximate the influence of any training point on $phi$ via: \n",
    "#### $$BIF(x_j, \\phi) = -Cov_{\\theta}(\\ell(x_j,\\theta), \\phi(\\theta))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3257d-5749-46b5-9c7b-9d9b37f145a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
