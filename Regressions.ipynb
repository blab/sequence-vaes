{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe18e5e-7510-4224-b7e1-1b1d2cc896aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2722cf-ef83-4b90-ba1a-0dd9bba0544a",
   "metadata": {},
   "source": [
    "## Standard VAE + Bedford VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520918e3-a0ea-4a3b-8b74-3c9dadae9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath = \"./VAE_standard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488c5d5-5217-4a1b-ba8e-1356dbdedea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(abspath)\n",
    "from models import DNADataset, ALPHABET, SEQ_LENGTH, LATENT_DIM, VAE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE as tsne\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import bedford_code.models_bedford as bedford\n",
    "from treetime.utils import datetime_from_numeric\n",
    "import pymc as pm\n",
    "from collections.abc import Iterable\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b14bb-bc7c-4639-aa76-a318cde01440",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# \"data\" directory is generated as shown in README.md file\n",
    "dataset = DNADataset(f\"{abspath}/../data/training_spike.fasta\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aabb-baf3-41eb-816d-0da2cce072df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981804a7-fe34-4eb8-b1f0-8384e6cdd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(ALPHABET) * SEQ_LENGTH\n",
    "# input_dim = 29903 * 5\n",
    "# input_dim = 29903\n",
    "\n",
    "# BEDFORD\n",
    "# vae_model = bedford.VAE(input_dim=len(bedford.ALPHABET) * bedford.SEQ_LENGTH, latent_dim=bedford.LATENT_DIM).to(DEVICE)\n",
    "# vae_model.load_state_dict(torch.load(f\"{abspath}/bedford_code/results_bedford/BEST_vae_ce_anneal.pth\"))\n",
    "#STANDARD\n",
    "vae_model = VAE(input_dim=input_dim, latent_dim=50).to(DEVICE)\n",
    "vae_model.load_state_dict(torch.load(f\"{abspath}/model_saves/standard_VAE_model_BEST.pth\", weights_only=True, map_location=DEVICE))\n",
    "\n",
    "\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f2801-0ae5-436e-924a-45d5bc7d130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = [\"training\", \"valid\", \"test\"]\n",
    "dset = dset[0]\n",
    "print(dset)\n",
    "abspath = \".\"\n",
    "dataset = DNADataset(f\"{abspath}/data/{dset}_spike.fasta\")\n",
    "new_dataset = np.array([dataset[x][0].numpy() for x in range(len(dataset))])\n",
    "vals = np.array([dataset[x][1] for x in range(len(dataset))])\n",
    "# labeling\n",
    "metadata = pd.read_csv(f\"{abspath}/data/all_data/all_metadata.tsv\", sep=\"\\t\")\n",
    "clade_labels = [metadata.loc[metadata.name == vals[i], \"clade_membership\"].values[0] for i in range(len(vals))]\n",
    "dates = [metadata.loc[metadata.name == vals[i], \"date\"].values[0] for i in range(len(vals))]\n",
    "dates = [datetime_from_numeric(x) for x in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b125fee-264b-42a3-83de-d3869d766661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, float)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "collection_dates = pd.DataFrame([[x] for i,x in enumerate(dates)], columns=[\"date\"])\n",
    "collection_dates.index = pd.to_datetime(collection_dates[\"date\"])\n",
    "collection_dates = collection_dates.groupby(pd.Grouper(freq='W'))\n",
    "collection_dates = list(collection_dates.groups.values())\n",
    "print(collection_dates)\n",
    "collection_dates = [collection_dates[0]] + [collection_dates[i] - collection_dates[i-1] for i in range(len(collection_dates)-1, 0, -1)][::-1]\n",
    "collection_dates = list(flatten([[i for j in range(x)] for i,x in enumerate(collection_dates)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac221f-ca25-459f-a23c-71ec771787dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_clade_labels = []\n",
    "for c in clade_labels:\n",
    "    if len(metadata[metadata.clade_membership == c]) > 5:\n",
    "        good_clade_labels.append(c)\n",
    "print(set(good_clade_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74eada1-25e4-41dc-ba6a-9f24752cd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(set(clade_labels))\n",
    "\n",
    "# clusters = np.sort(np.array(list(set(good_clade_labels))))\n",
    "clusters = np.sort(np.array(list(set(clade_labels))))\n",
    "print(clusters)\n",
    "get_clade = lambda x: [True if elem == x else False for elem in clade_labels]\n",
    "\n",
    "indexes = tuple([np.arange(len(clade_labels))[get_clade(x)] for x in clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446a91f-f998-4527-9db5-3d53018caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vals = []\n",
    "for v in vals:\n",
    "    if metadata.loc[metadata.name == v, \"clade_membership\"].values[0] in clusters:\n",
    "        new_vals.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16366d71-75f0-46f8-954a-f92fae51214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = pd.read_csv(f\"{abspath}/data/all_data/all_branches.tsv\", sep=\"\\t\")\n",
    "node_dict = {x:i for i,x in enumerate(new_vals)}\n",
    "pairs = []\n",
    "for p,c in zip(parents[\"parent\"], parents[\"child\"]):\n",
    "    i1 = node_dict.get(p, None)\n",
    "    i2 = node_dict.get(c, None)\n",
    "\n",
    "    if i1 and i2:\n",
    "        pairs.append((i1,i2))\n",
    "\n",
    "pairs = np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f12047-5ce8-4c12-a4a0-302d9603f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"gist_ncar\")\n",
    "colors = [cmap(x) for x in np.arange(len(indexes)) / len(indexes)]\n",
    "\n",
    "ranges = np.concatenate(indexes)\n",
    "\n",
    "X = torch.tensor(new_dataset[ranges,:,:])\n",
    "print(\"X shape\")\n",
    "print(new_dataset.shape)\n",
    "print(X.shape)\n",
    "# X = X.to(DEVICE)\n",
    "X = X.view(X.size(0), -1).to(DEVICE)\n",
    "pca = PCA(n_components=3, svd_solver=\"full\")\n",
    "\n",
    "\n",
    "recon = None\n",
    "Z_mean = None\n",
    "Z_embedded = None\n",
    "scatterplot = None\n",
    "with torch.no_grad():\n",
    "    # STANDARD\n",
    "    Z_mean, Z_logvar = vae_model.encoder.forward(X)\n",
    "    recon = vae_model.decoder.forward(Z_mean)\n",
    "    recon = recon.view(recon.shape[0], -1).cpu()\n",
    "    Z_mean = Z_mean.cpu()\n",
    "    Z_std = torch.exp(0.5 * Z_logvar).cpu()\n",
    "\n",
    "    # BEDFORD\n",
    "    # recon, Z_mean, Z_logvar = vae_model.forward(X)\n",
    "    # recon = recon.cpu().numpy()\n",
    "    # Z_mean = Z_mean.cpu().numpy()\n",
    "    \n",
    "    print(\"\\nRecon shape\")\n",
    "    print(recon.shape)\n",
    "    \n",
    "    # Z_embedded = tsne(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(X = Z_mean)\n",
    "    pca.fit(Z_mean)\n",
    "    Z_embedded = pca.transform(Z_mean - torch.mean(Z_mean))\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    tot = np.sum(variances)\n",
    "    print(variances)\n",
    "    print(f\"total variance: {tot}\")\n",
    "    curr = 0\n",
    "    \n",
    "\n",
    "# %matplotlib widget\n",
    "# plt.ion()\n",
    "fig,ax = plt.subplots(1,1,figsize=(14,10),subplot_kw=dict(projection=\"3d\"))\n",
    "\n",
    "# RELATIONS\n",
    "# for i,arr in enumerate(indexes):\n",
    "#     ax.scatter(Z_embedded[arr,0], Z_embedded[arr,1], Z_embedded[arr, 2], label=clade_labels[arr[0]], alpha=0.6, color=colors[i], s=150)\n",
    "#     curr += len(arr)\n",
    "# l1 = 0.1\n",
    "# l2 = 0\n",
    "# ax.legend(bbox_to_anchor=(l1,l2,l1+1,l2+1))\n",
    "\n",
    "# TIME \n",
    "scatterplot = ax.scatter(Z_embedded[:,0], Z_embedded[:,1], Z_embedded[:,2], c=collection_dates, cmap=\"viridis\", s=150)\n",
    "fig.colorbar(scatterplot, ax=ax, shrink=0.5)\n",
    "\n",
    "ax.set_title(\"PCA visualization of (standard) VAE latent space\")\n",
    "for p in pairs:\n",
    "    ax.plot(Z_embedded[p,0], Z_embedded[p,1], Z_embedded[p,2], color=\"gray\", alpha=0.5)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "plt.show()\n",
    "\n",
    "# plotting_dict = pd.DataFrame([(x1,x2,x3,c) for (x1,x2,x3),c in zip(Z_embedded, collection_dates)], columns=[\"dim0\",\"dim1\",\"dim2\",\"date\"])\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "# alt.Chart(plotting_dict).mark_circle(size=60).encode(\n",
    "#     x='dim0',\n",
    "#     y='dim1',\n",
    "#     # z='dim3',\n",
    "#     color='date',\n",
    "#     tooltip=['dim0', 'dim1', 'date']\n",
    "# ).properties(\n",
    "#     width=1000,\n",
    "#     height=550\n",
    "# ).interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552882a7-0398-443a-9612-185e6c1b8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_.shape)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1d5db-d8c4-4d4e-99a4-f432aa07bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = X.view(X.shape[0], -1, len(ALPHABET)).cpu().numpy().astype(\"int\")\n",
    "genome = np.matmul(genome, np.arange(len(ALPHABET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64728193-57cd-46de-b29a-634359f10bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, float)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a4284-1b16-4801-9a8b-621ff1454ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Z_embedded.shape[0]\n",
    "print(N)\n",
    "hamming = list(flatten([np.sum(np.not_equal(genome[i,:],genome[(i+1):,:]),axis=-1) for i in range(N-1)]))\n",
    "euclid = list(flatten([np.linalg.norm((Z_embedded[(i+1):,:] - Z_embedded[i,:]), axis=-1) for i in range(N-1)]))\n",
    "\n",
    "fig,arr = plt.subplots(1,1,figsize=(14,10))\n",
    "arr.set_title(\"Hamming vs. Euclidean dist\")\n",
    "arr.scatter(hamming, euclid, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa0667-7005-4143-b9f8-0d9dd191317b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "782d8349-65d6-4135-8f36-acd1e2a34563",
   "metadata": {},
   "source": [
    "## GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb3e9f-8579-4246-a13b-b2b22fac7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37a6c0-cd54-4d92-bd73-05ce7ca9c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(new_dataset[ranges,:,:])\n",
    "# X = X.to(DEVICE)\n",
    "X = X.view(X.size(0), -1).to(DEVICE)\n",
    "print(\"X shape\")\n",
    "print(new_dataset.shape)\n",
    "print(X.shape)\n",
    "\n",
    "pca = PCA(n_components=3, svd_solver=\"full\")\n",
    "\n",
    "Z_mean = None\n",
    "Z_embedded = None\n",
    "with torch.no_grad():\n",
    "    # STANDARD\n",
    "    Z_mean, Z_logvar = vae_model.encoder.forward(X)\n",
    "    recon = vae_model.decoder.forward(Z_mean)\n",
    "    recon = recon.view(recon.shape[0], -1).cpu()\n",
    "    Z_mean = Z_mean.cpu()\n",
    "    Z_std = torch.exp(0.5 * Z_logvar).cpu()\n",
    "    # BEDFORD\n",
    "    # recon, Z_mean, Z_logvar = vae_model.forward(X)\n",
    "    # recon = recon.cpu().numpy()\n",
    "    # Z_mean = Z_mean.cpu().numpy()\n",
    "\n",
    "    pca.fit(Z_mean)\n",
    "    Z_embedded = pca.transform(Z_mean - torch.mean(Z_mean))\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    tot = np.sum(variances)\n",
    "    print(\"\\n\",variances)\n",
    "    print(f\"total variance: {tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b70cd-03b0-4af1-a7c8-af4ca7d9d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(f\"{abspath}/data/all_data/all_metadata.tsv\", sep=\"\\t\")\n",
    "clade_labels = [metadata.loc[metadata.name == vals[i], \"clade_membership\"].values[0] for i in range(len(vals))]\n",
    "dates = [metadata.loc[metadata.name == vals[i], \"date\"].values[0] for i in range(len(vals))]\n",
    "dates = [datetime_from_numeric(x) for x in dates]\n",
    "\n",
    "coords = [(x1,x2,x3,t,c) for (x1,x2,x3),t,c in zip(Z_embedded, dates,clade_labels)]\n",
    "coords = pd.DataFrame(data=coords, columns=[\"dim0\",\"dim1\",\"dim2\",\"time\",\"clade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c3f91-4e1b-48ee-bb70-924d0d915885",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_coords = coords.groupby(\"time\")[[\"dim0\",\"dim1\",\"dim2\"]].median().resample(\"ME\").median().dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295c216-0690-4398-9759-489c4553ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ubound = len(avg_coords)\n",
    "\n",
    "plt.ioff()\n",
    "fig,ax = plt.subplots(1,3,figsize=(22,8))\n",
    "for i,d in enumerate([\"dim0\",\"dim1\",\"dim2\"]):\n",
    "    ax[i].plot(np.linspace(0,ubound,num=len(avg_coords)), avg_coords[d])\n",
    "    ax[i].set_title(f\"time vs. {d}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9073b3-ad99-4261-862f-5e7c477987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(0,ubound,num=len(avg_coords)).astype(\"float32\")[:,np.newaxis]\n",
    "# import theano.tensor as tt\n",
    "def build_coords_model(dim):\n",
    "    y_vals = avg_coords[dim].values.astype('float32')\n",
    "    print(x_vals.shape, y_vals.shape)\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # l = pm.HalfCauchy('l', beta=20)\n",
    "        l = pm.Uniform('l', 0, 30)\n",
    "\n",
    "        # Covariance function\n",
    "        log_s2_f = pm.Uniform('log_s2_f', lower=-10, upper=5)\n",
    "        s2_f = pm.Deterministic('s2_f', np.exp(log_s2_f))\n",
    "        f_cov = s2_f * pm.gp.cov.ExpQuad(input_dim=1, ls=l)\n",
    "\n",
    "        # Sigma = 1/lam\n",
    "        s2_n = pm.HalfCauchy('s2_n', beta=5)\n",
    "\n",
    "        gp = pm.gp.Latent(cov_func=f_cov)\n",
    "        f = gp.prior(\"f\",X=x_vals)\n",
    "\n",
    "        df = 1 + pm.Gamma(\"df\",alpha=2,beta=1)\n",
    "        y_obs = pm.StudentT(\"y\", mu=f, lam=1.0 / s2_n, nu=df, observed=y_vals)\n",
    "\n",
    "        trace = pm.sample(draws=4000)\n",
    "    return trace, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ca1df-020a-4162-b5c4-35b3f90b0a54",
   "metadata": {},
   "source": [
    "### Run and save regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34fc98-e3ea-4944-848d-0c0be7688260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cloudpickle\n",
    "\n",
    "ret_vals = [build_coords_model(d) for d in [\"dim0\",\"dim1\",\"dim2\"]]\n",
    "\n",
    "GPs = [x[1] for x in ret_vals]\n",
    "idata = [x[0] for x in ret_vals]\n",
    "\n",
    "abspath = \".\"\n",
    "dict_to_save = {x:(idata[i],GPs[i]) for i,x in enumerate([\"dim0\",\"dim1\",\"dim2\"])}\n",
    "with open(f\"{abspath}/king_regression_data.pkl\",\"wb\") as buff:\n",
    "    cloudpickle.dump(dict_to_save, buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd08cc-d6ff-4997-a9b6-a2546156f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "for n,d in zip([\"dim0\",\"dim1\",\"dim2\"],idata):\n",
    "    print(n)\n",
    "    n_nonconverged = int(\n",
    "        np.sum(az.rhat(d)[[\"l\", \"log_s2_f\", \"s2_n\", \"f_rotated_\", \"df\"]].to_array() > 1.03).values\n",
    "    )\n",
    "    if n_nonconverged == 0:\n",
    "        print(\"No Rhat values above 1.03, \\N{check mark}\")\n",
    "    else:\n",
    "        print(f\"The MCMC chains for {n_nonconverged} RVs appear not to have converged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33116d0e-c4b7-4468-8f9d-d426f7f71f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the samples from the gp posterior with samples and shading\n",
    "from pymc.gp.util import plot_gp_dist\n",
    "\n",
    "idata = None\n",
    "with open (f\"{abspath}/king_regression_data.pkl\", \"rb\") as buff:\n",
    "    idata = pickle.load(buff)\n",
    "    idata = [idata[x] for x in [\"dim0\",\"dim1\",\"dim2\"]]\n",
    "\n",
    "for d,n in zip(idata,[\"dim0\",\"dim1\",\"dim2\"]):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.gca()\n",
    "    disp_x_vals = np.arange(len(avg_coords))\n",
    "    \n",
    "    f_post = az.extract(d, var_names=\"f\").transpose(\"sample\", ...)\n",
    "    plot_gp_dist(ax, f_post, disp_x_vals)\n",
    "    ax.scatter(disp_x_vals, avg_coords[n])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44135907-1fd1-40fd-85bb-090b66bf6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ubound = len(avg_coords)\n",
    "new_x_vals = np.linspace(0,ubound+2,num=len(avg_coords)+2).astype(\"float32\")[:,np.newaxis]\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # add the GP conditional to the model, given the new X values\n",
    "    f_pred = pm.gp.conditional(\"f_pred\", X_new, jitter=1e-4)\n",
    "\n",
    "    # Sample from the GP conditional distribution\n",
    "    idata.extend(pm.sample_posterior_predictive(idata[0], var_names=[\"f_pred\"]))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.gca()\n",
    "\n",
    "f_pred = az.extract(idata.posterior_predictive, var_names=\"f_pred\").transpose(\"sample\", ...)\n",
    "plot_gp_dist(ax, f_pred, X_new)\n",
    "ax.scatter(disp_x_vals, avg_coords[\"dim0\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94e579-e818-4356-a024-c98d3eba83e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
