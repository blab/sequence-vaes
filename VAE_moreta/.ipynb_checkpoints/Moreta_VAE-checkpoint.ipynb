{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4e94d-6911-4033-928b-a8a2a6216be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed0df4-9e78-4c15-b5ac-06e8f300683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath = \"..\"\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495919f8-2487-4233-a69d-bd1e71943906",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from models import DNADataset, ALPHABET, SEQ_LENGTH, LATENT_DIM\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.append(\"../../DRAUPNIR_ASR/draupnir/src/\")\n",
    "import draupnir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50877b1-c65c-40b0-a07f-6b459ae15328",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = DNADataset(f\"{abspath}/data/alignment.fasta\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872882f3-841f-4bae-86e4-e5450d2d0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "from draupnir import str2bool, str2None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0223db6-c928-42a5-ba38-fbd179945636",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Draupnir args\",formatter_class=RawTextHelpFormatter)\n",
    "parser.add_argument('-name','--dataset-name', type=str, nargs='?',\n",
    "                    default=\"simulations_blactamase_1\",\n",
    "                    #default=\"ABO\", #TODO: fix fasta and tree file to have same names\n",
    "                    help='Dataset project name, look at draupnir.available_datasets()')\n",
    "parser.add_argument('-use-custom','--use-custom', type=str2bool, nargs='?',\n",
    "                    default=False,\n",
    "                    help='True: Use a custom dataset (create your own dataset). First create a folder with the same name as args.dataset_name where to store the necessary files here: draupnir/src/draupnir/data) '\n",
    "                         'False: Use a default dataset (those shown in the paper) (they will automatically be downloaded at draupnir/src/draupnir/data)')\n",
    "parser.add_argument('-n', '--num-epochs', default=15000, type=int, help='number of training epochs')\n",
    "parser.add_argument('--alignment-file', type=str2None, nargs='?',\n",
    "                    #default=\"/home/lys/Dropbox/PhD/DRAUPNIR_ASR/PF0096/PF0096.mafft\",\n",
    "                    default=None,\n",
    "                    help='Path to alignment in fasta format (use with args.use_custom = True), with ALIGNED sequences. '\n",
    "                         'PLEASE make sure that the fasta header names and the names in the tree are the same')\n",
    "parser.add_argument('--tree-file', type=str2None, nargs='?',\n",
    "                    #default=\"/home/lys/Dropbox/PhD/DRAUPNIR_ASR/PF0096/PF0096.fasta.treefile\",\n",
    "                    default=None,\n",
    "                    help='Path to newick tree (in format 1 from ete3) (use with args.use_custom = True).'\n",
    "                         'PLEASE make sure that the fasta header names and the names in the tree are the same')\n",
    "parser.add_argument('--fasta-file', type=str2None, nargs='?',\n",
    "                    default=None,\n",
    "                    help='Path to fasta file (use with args.use_custom = True) with UNALIGNED sequences and NO tree (tree is inferred using IQtree). '\n",
    "                         'PLEASE make sure that the fasta header names and the names in the tree are the same')\n",
    "parser.add_argument('--leaf-embeddings', type=str2None, nargs='?',\n",
    "                    default=None,\n",
    "                    help='Path to dataframe containing pre-computed embeddings for the leaf sequences (i.e ESMB embeddings)') #TODO: IMPLEMENT\n",
    "parser.add_argument('-build', '--build-dataset', default=False, type=str2bool,\n",
    "                    help='True: Create and store the dataset from a given alignment file/tree or the unaligned sequences;'\n",
    "                         'False: Use previously stored data files under folder with -dataset-name or at draupnir/src/draupnir/data. '\n",
    "                         'Once you have built once the dataset you do not have to do it again (if everything went fine)'\n",
    "                         'Further customization can be found under draupnir/src/draupnir/datasets.py')\n",
    "parser.add_argument('-bsize','--batch-size', default=1, type=str2None,nargs='?',help='set batch size.\\n '\n",
    "                                                            'Set to 1 to NOT batch (batch_size == 1 batch == entire dataset).\\n '\n",
    "                                                            'Set to None it automatically suggests a batch size and activates batching (it is slow, only use for very large datasets).\\n '\n",
    "                                                            'If batch_by_clade=True: 1 batch= 1 clade (size given by clades_dict).'\n",
    "                                                            'Else set the batchsize to the given number')\n",
    "parser.add_argument('-aa-probs', default=21, type=int, help='21: 20 amino acids,1 gap probabilities \\n '\n",
    "                                                            ' 24: 23 amino acids, 1 gap')\n",
    "parser.add_argument('-n-samples','-n_samples', default=10, type=int, help='Number of samples (sequences sampled) per node')\n",
    "parser.add_argument('-use-blosum','--use-blosum', type=str2bool, nargs='?',default=True,help='Use blosum matrix embedding')\n",
    "parser.add_argument('-subs_matrix', default=\"BLOSUM62\", type=str, help='blosum matrix to create blosum embeddings, choose one from ~/anaconda3/pkgs/biopython-1.76-py37h516909a_0/lib/python3.7/site-packages/Bio/Align/substitution_matrices/data')\n",
    "parser.add_argument('-embedding-dim', default=50, type=int, help='Blosum embedding dim')\n",
    "parser.add_argument('-use-cuda', type=str2bool, nargs='?', default=True,\n",
    "                    help='True: Use GPU; False: Use CPU')\n",
    "parser.add_argument('-use-scheduler', type=str2bool, nargs='?', default=False, help='Use learning rate scheduler, to modify the learning rate during training. Only used with 1 large dataset in the paper')\n",
    "parser.add_argument('-test-frequency', default=100, type=int, help='sampling frequency (in epochs) during training, every <n> epochs, sample')\n",
    "parser.add_argument('-guide', '--select_guide', default=\"delta_map\", type=str,help='choose a guide, available types: \"delta_map\" , \"diagonal_normal\" or \"variational\"')\n",
    "#Highlight: Sample from a pre-trained model\n",
    "parser.add_argument('-load-pretrained-path', type=str, nargs='?',default=\"None\",\n",
    "                    help='Load pretrained Draupnir Checkpoints (folder path) to generate samples')\n",
    "parser.add_argument('-generate-samples', type=str2bool, nargs='?', default=False,help='Load fixed pretrained parameters (stored in Draupnir Checkpoints) and generate new samples')\n",
    "#Highlight: EXPERIMENTAL FEATURES\n",
    "parser.add_argument('-one-hot','--one-hot-encoded', type=str2bool, nargs='?',\n",
    "                    default=False,\n",
    "                    help='Build a one-hot-encoded dataset. Do not use, for now, Draupnir works with blosum-encoded and integers as amino acid representations, '\n",
    "                         'so this is not needed for Draupnir inference at the moment')\n",
    "parser.add_argument('-bbc','--batch-by-clade', type=str2bool, nargs='?', default=False, help='Experimental. Use the leaves divided by their corresponding clades into batches. Do not use with leaf-testing')\n",
    "parser.add_argument('-pdb_folder', default=None, type=str,\n",
    "                    help='Path to folder of PDB structures. The engine can read them and parse them into a dataset that the model can use.')\n",
    "parser.add_argument('-angles','--infer-angles', type=str2bool, nargs='?', default=False,help='Experimental. Additional Inference of angles. Use only with sequences associated PDB structures and their angles.')\n",
    "parser.add_argument('-kappa-addition', default=5, type=int, help='lower bound on the angles distribution parameters')\n",
    "parser.add_argument('-plate','--plating',  type=str2bool, nargs='?', default=False, help='Plating/Subsampling the mapping of the sequences (ONLY the sequences, not the latent space, '\n",
    "                                                                                         'see example in DRAUPNIRModel_classic_plating under models.py).\\n'\n",
    "                                                                                         ' Remember to set plating/subsampling size, otherwise it is done automatically')\n",
    "parser.add_argument('-plate-size','--plating_size', type=str2None, nargs='?',default=None,help='Set plating/subsampling size:\\n '\n",
    "                                                                'If set to None it automatically suggests a plate size, only if args.plating is TRUE!. Otherwise it remains as None and no plating occurs\\n '\n",
    "                                                                'Else it sets the plate size to a given integer')\n",
    "parser.add_argument('-plate-idx-shuffle','--plate-unordered', type=str2bool, nargs='?',const=None, default=False,help='When subsampling/plating, shuffle (True) or not (False) the idx of the sequences which are given in tree level order')\n",
    "parser.add_argument('-position-embedding-dim', default=30, type=int, help='Tree position embedding dimension size')\n",
    "parser.add_argument('-max-indel-size', default=5, type=int, help='maximum insertion deletion size (not used)')\n",
    "parser.add_argument('-activate-elbo-convergence', default=False, type=bool, help='extends the running time until a convergence criteria in the elbo loss is met')\n",
    "parser.add_argument('-activate-entropy-convergence', default=False, type=bool, help='extends the running time until a convergence criteria in the sequence entropy is met')\n",
    "#TODO: Ray HPO? Would need to do for each protein family\n",
    "parser.add_argument('-d', '--config-dict', default=None,type=str, help=\"Used with parameter search\")\n",
    "parser.add_argument('--parameter-search', type=str2bool, default=False, help=\"Activates a mini grid search for parameter search. TODO: Improve\") #TODO: Change to something that makes more sense\n",
    "args = parser.parse_args([\"--dataset-name\", \"benchmark_randall_original_naming\", \n",
    "                          \"--alignment-file\", \"../../DRAUPNIR_ASR/data/benchmark_randall_original_naming/benchmark_randall_original_naming.mafft\",\n",
    "                         \"--tree-file\",\"/home/averma2/code/DRAUPNIR_ASR/data/benchmark_randall_original_naming/RandallBenchmarkTree_OriginalNaming.tree\"])\n",
    "args.__dict__[\"device\"] = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0749c-7986-4019-88af-06ccfc3791a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"args:\\n------------------------------\")\n",
    "for k,v in sorted(vars(args).items()):\n",
    "    print(f\"%-40s:\\t{v}\"%f\"{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f41a53-1152-436f-8fb7-828b58cd3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildConfig = namedtuple('BuildConfig',['alignment_file','use_ancestral','n_test','build_graph',\"aa_probs\",\"triTSNE\",\n",
    "                                        \"leaves_testing\",\"script_dir\",\"no_testing\"])\n",
    "SettingsConfig = namedtuple(\"SettingsConfig\",[\"one_hot_encoding\", \"model_design\",\"aligned_seq\",\"data_folder\",\"full_name\",\"tree_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6568e08-0c1b-42ad-b3c3-88da281d4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_config = {\n",
    "            \"lr\": 1e-3,\n",
    "            \"beta1\": 0.9, #coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "            \"beta2\": 0.999,\n",
    "            \"eps\": 1e-8,#term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "            \"weight_decay\": 0,#weight_decay: weight decay (L2 penalty) (default: 0)\n",
    "            \"clip_norm\": 10,#clip_norm: magnitude of norm to which gradients are clipped (default: 10.0)\n",
    "            \"lrd\": 1, #rate at which learning rate decays (default: 1.0)\n",
    "            \"z_dim\": 30,\n",
    "            \"gru_hidden_dim\": 60, #60\n",
    "        }\n",
    "\n",
    "root_sequence_name = None\n",
    "name = \"benchmark_randall_original_naming\"\n",
    "\n",
    "build_config = BuildConfig(alignment_file='../../DRAUPNIR_ASR/data/benchmark_randall_original_naming/benchmark_randall_original_naming.mafft', \n",
    "            use_ancestral=True, \n",
    "            n_test=0, \n",
    "            build_graph=True, \n",
    "            aa_probs=21, \n",
    "            triTSNE=False, \n",
    "            leaves_testing=False, \n",
    "            script_dir='.', \n",
    "            no_testing=False)\n",
    "\n",
    "settings_config = SettingsConfig(one_hot_encoding=False, \n",
    "               model_design='GP_VAE', \n",
    "               aligned_seq=True, \n",
    "               data_folder='/home/averma2/code/DRAUPNIR_ASR/data/benchmark_randall_original_naming', \n",
    "               full_name=\"Randall's Coral fluorescent proteins (CFP) benchmark dataset\", \n",
    "               tree_file='/home/averma2/code/DRAUPNIR_ASR/data/benchmark_randall_original_naming/RandallBenchmarkTree_OriginalNaming.tree')\n",
    "\n",
    "results_dir = os.getcwd() + \"/results\"\n",
    "\n",
    "script_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354d3e9-b22d-4d9d-856c-1b8078784240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load,test_load,additional_load,build_config = draupnir.main.load_data(name,settings_config,build_config,param_config,results_dir,script_dir,args)\n",
    "additional_info = draupnir.utils.extra_processing(additional_load.ancestor_info_numbers, additional_load.patristic_matrix_full,results_dir,args,build_config)\n",
    "train_load,test_load,additional_load= draupnir.load_utils.datasets_pretreatment(name,root_sequence_name,train_load,test_load,additional_load,build_config,args,settings_config,script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503551af-9ced-4fc3-8728-80da60a28d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"train_load\",\"test_load\",\"additional_load\",\"build_config\",\"additional_info\"]\n",
    "vs = [train_load,test_load,additional_load,build_config,additional_info]\n",
    "\n",
    "for i in range(len(vs)):\n",
    "    info_dict = vs[i]._asdict()\n",
    "    for key,val in info_dict.items():\n",
    "        if str(type(val)) == \"<class 'torch.Tensor'>\":\n",
    "            vs[i] = vs[i]._replace(**{key:val.to(args.device)})\n",
    "\n",
    "train_load = vs[0]\n",
    "test_load = vs[1]\n",
    "additional_load = vs[2]\n",
    "build_config = vs[3]\n",
    "additional_info = vs[4]\n",
    "\n",
    "for i,v in enumerate(vs):\n",
    "    print(names[i] + \"\\n-----------\")\n",
    "    info_dict = v._asdict()\n",
    "    for key,val in info_dict.items():        \n",
    "        print(f\"%-30s:\\t{str(type(val))}\"%f\"{key}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488f064-d356-47ca-9ab4-235fe2e79c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.one_hot_encoded:\n",
    "    raise ValueError(\"Please set one_hot_encoding to False\")\n",
    "    print(\"Starting Draupnir ...\")\n",
    "    print(\"Dataset: {}\".format(name))\n",
    "    print(\"Number epochs: {}\".format(args.num_epochs))\n",
    "    print(\"Z/latent Size: {}\".format(param_config[\"z_dim\"]))\n",
    "    print(\"GRU hidden size: {}\".format(param_config[\"gru_hidden_dim\"]))\n",
    "    print(\"Number train sequences: {}\".format(train_load.dataset_train.shape[0]))\n",
    "    n_test = [test_load.dataset_test.shape[0] if test_load.dataset_test is not None else 0][0]\n",
    "    print(\"Number test sequences: {}\".format(n_test))\n",
    "    print(\"Selected Substitution matrix : {}\".format(args.subs_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70d762-dbc9-4ea4-892d-5f8dc6a55f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Draupnir with the entire tree at once, not batching\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_device(args.device)\n",
    "if not args.batch_by_clade:\n",
    "    clades_dict=None\n",
    "else:\n",
    "    clades_dict = additional_load.clades_dict_leaves\n",
    "graph_coo = None #Highlight: use only with the GNN models (7)---> Otherwise it is found in additional_info\n",
    "draupnir.main.draupnir_train(train_load,\n",
    "                            test_load,\n",
    "                            additional_load,\n",
    "                            additional_info,\n",
    "                            build_config,\n",
    "                            settings_config,\n",
    "                            param_config,\n",
    "                            args.n_samples,\n",
    "                            args,\n",
    "                            script_dir,\n",
    "                            results_dir,\n",
    "                            graph_coo,\n",
    "                            clades_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cca250-8c7c-4300-91d3-95da9e72a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
