{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0b583e-c368-4d34-8a03-700726373987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../VAE_standard\")\n",
    "from models import DNADataset, ALPHABET, SEQ_LENGTH, LATENT_DIM, VAE\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import utils\n",
    "\n",
    "import Bio.Data.CodonTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b21b180-5e49-4697-9785-cea199205629",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DNADataset(f\"../data/training_spike.fasta\")\n",
    "sequences = [utils.get_genome(np.dot(x[0], np.arange(len(ALPHABET)))) for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1086529b-7849-4fd5-ae1b-f4f52d19b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/averma2/miniforge3/envs/Moreta_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "MAX_TOKEN_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8e5910-5dd9-4910-94b1-e505d64461dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 Standard, SGC0\n",
      "\n",
      "  |  T      |  C      |  A      |  G      |\n",
      "--+---------+---------+---------+---------+--\n",
      "T | TTT F   | TCT S   | TAT Y   | TGT C   | T\n",
      "T | TTC F   | TCC S   | TAC Y   | TGC C   | C\n",
      "T | TTA L   | TCA S   | TAA Stop| TGA Stop| A\n",
      "T | TTG L(s)| TCG S   | TAG Stop| TGG W   | G\n",
      "--+---------+---------+---------+---------+--\n",
      "C | CTT L   | CCT P   | CAT H   | CGT R   | T\n",
      "C | CTC L   | CCC P   | CAC H   | CGC R   | C\n",
      "C | CTA L   | CCA P   | CAA Q   | CGA R   | A\n",
      "C | CTG L(s)| CCG P   | CAG Q   | CGG R   | G\n",
      "--+---------+---------+---------+---------+--\n",
      "A | ATT I   | ACT T   | AAT N   | AGT S   | T\n",
      "A | ATC I   | ACC T   | AAC N   | AGC S   | C\n",
      "A | ATA I   | ACA T   | AAA K   | AGA R   | A\n",
      "A | ATG M(s)| ACG T   | AAG K   | AGG R   | G\n",
      "--+---------+---------+---------+---------+--\n",
      "G | GTT V   | GCT A   | GAT D   | GGT G   | T\n",
      "G | GTC V   | GCC A   | GAC D   | GGC G   | C\n",
      "G | GTA V   | GCA A   | GAA E   | GGA G   | A\n",
      "G | GTG V   | GCG A   | GAG E   | GGG G   | G\n",
      "--+---------+---------+---------+---------+--\n"
     ]
    }
   ],
   "source": [
    "x = Bio.Data.CodonTable.standard_dna_table\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca04ae6-45d4-48fc-8e7a-5d7a14e5895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"\".join(sequences[0])\n",
    "codon_seq = \"\".join([x.forward_table.get(seq[3*i:3*i+3], \"stop\") for i in range(len(seq) // 3 - 1)])\n",
    "codon_subseq = codon_seq[:MAX_TOKEN_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5329838c-7575-42a1-9aab-c355182ab8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3822\n",
      "1273\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(seq))\n",
    "print(len(codon_seq))\n",
    "print(len(codon_subseq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d11e07fd-24c2-4ef3-b1a3-a56540b7a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '.', '<cls>', '<eos>', '<mask>', '<null_1>', '<pad>', '<unk>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "k = sorted(list(tokenizer.get_vocab().keys()))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0264fce-d620-4543-bfe7-6cd09fc207b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPECIAL_TOKENS_ATTRIBUTES', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_add_tokens', '_additional_special_tokens', '_auto_class', '_batch_encode_plus', '_batch_prepare_for_model', '_bos_token', '_call_one', '_cls_token', '_convert_id_to_token', '_convert_token_to_id', '_convert_token_to_id_with_added_voc', '_create_repo', '_create_trie', '_decode', '_decode_use_source_tokenizer', '_encode_plus', '_eos_token', '_eventual_warn_about_too_long_sequence', '_eventually_correct_t5_max_length', '_from_pretrained', '_get_files_timestamps', '_get_padding_truncation_strategies', '_id_to_token', '_in_target_context_manager', '_mask_token', '_pad', '_pad_token', '_pad_token_type_id', '_processor_class', '_save_pretrained', '_sep_token', '_set_processor_class', '_switch_to_input_mode', '_switch_to_target_mode', '_token_to_id', '_tokenize', '_unk_token', '_upload_modified_files', 'add_special_tokens', 'add_tokens', 'added_tokens_decoder', 'added_tokens_encoder', 'additional_special_tokens', 'additional_special_tokens_ids', 'all_special_ids', 'all_special_tokens', 'all_special_tokens_extended', 'all_tokens', 'as_target_tokenizer', 'batch_decode', 'batch_encode_plus', 'bos_token', 'bos_token_id', 'build_inputs_with_special_tokens', 'clean_up_tokenization', 'clean_up_tokenization_spaces', 'cls_token', 'cls_token_id', 'convert_ids_to_tokens', 'convert_tokens_to_ids', 'convert_tokens_to_string', 'create_token_type_ids_from_sequences', 'decode', 'deprecation_warnings', 'encode', 'encode_plus', 'eos_token', 'eos_token_id', 'from_pretrained', 'get_added_vocab', 'get_special_tokens_mask', 'get_vocab', 'get_vocab_size', 'id_to_token', 'init_inputs', 'init_kwargs', 'is_fast', 'mask_token', 'mask_token_id', 'max_len_sentences_pair', 'max_len_single_sentence', 'max_model_input_sizes', 'model_input_names', 'model_max_length', 'name_or_path', 'num_special_tokens_to_add', 'pad', 'pad_token', 'pad_token_id', 'pad_token_type_id', 'padding_side', 'prepare_for_model', 'prepare_for_tokenization', 'prepare_seq2seq_batch', 'pretrained_init_configuration', 'pretrained_vocab_files_map', 'push_to_hub', 'register_for_auto_class', 'sanitize_special_tokens', 'save_pretrained', 'save_vocabulary', 'sep_token', 'sep_token_id', 'slow_tokenizer_class', 'special_tokens_map', 'special_tokens_map_extended', 'token_to_id', 'tokenize', 'tokens_trie', 'truncate_sequences', 'truncation_side', 'unique_no_split_tokens', 'unk_token', 'unk_token_id', 'verbose', 'vocab_files_names', 'vocab_size']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde55b88-409f-4f93-aead-795f9cda2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1,  ..., 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "test_input = tokenizer(codon_subseq, return_tensors=\"pt\", add_special_tokens=False)\n",
    "print(test_input[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d0aff0-68ea-4383-9104-ab0700a9a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test = model(**test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c728b2-e2df-44e3-bccb-29b41a3fd7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskedLMOutput(loss=None, logits=tensor([[[-11.1755, -21.5964, -12.7069,  ..., -16.2963, -16.2876, -21.5850],\n",
      "         [-11.0088, -21.2710, -11.9138,  ..., -16.1666, -16.2621, -21.2622],\n",
      "         [-10.3287, -22.3205, -11.6068,  ..., -16.4872, -16.5031, -22.3068],\n",
      "         ...,\n",
      "         [-10.8905, -20.7800,  -9.2887,  ..., -16.4550, -16.3657, -20.7865],\n",
      "         [ -9.2913, -19.5699,  -8.0398,  ..., -16.0253, -16.2629, -19.5651],\n",
      "         [ -8.5411, -18.0649,  -4.8223,  ..., -16.0127, -16.0276, -18.0695]]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9aea53ef-0705-45b8-930c-482915fa48da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EsmForMaskedLM(\n",
      "  (esm): EsmModel(\n",
      "    (embeddings): EsmEmbeddings(\n",
      "      (word_embeddings): Embedding(33, 320, padding_idx=1)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(1026, 320, padding_idx=1)\n",
      "    )\n",
      "    (encoder): EsmEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x EsmLayer(\n",
      "          (attention): EsmAttention(\n",
      "            (self): EsmSelfAttention(\n",
      "              (query): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (key): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (value): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (rotary_embeddings): RotaryEmbedding()\n",
      "            )\n",
      "            (output): EsmSelfOutput(\n",
      "              (dense): Linear(in_features=320, out_features=320, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (intermediate): EsmIntermediate(\n",
      "            (dense): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          )\n",
      "          (output): EsmOutput(\n",
      "            (dense): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (contact_head): EsmContactPredictionHead(\n",
      "      (regression): Linear(in_features=120, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): EsmLMHead(\n",
      "    (dense): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=320, out_features=33, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
