{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b649b0d-4293-46f4-b731-ea1274213acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537f616-3b1e-4557-8553-247ed276225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synthetic_data(N=50):\n",
    "    xs=ys=-2\n",
    "    xe=ye=2\n",
    "    \n",
    "    X1 = np.linspace(xs,xe,N)\n",
    "    X2 = np.linspace(ys,ye,N)\n",
    "    \n",
    "    X = np.meshgrid(X1,X2)\n",
    "    X = np.stack([x.ravel()[:None] for x in X], axis=-1)\n",
    "    \n",
    "    Y = ((np.square(X[:,0]) + np.square(X[:,1])) <= 1).astype(\"int\")\n",
    "\n",
    "    return torch.from_numpy(X).float(), torch.from_numpy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4aea3b-dc55-4e92-82d2-15881262c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, non_linear_activation=nn.ReLU(), input_dim=2, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.non_linear_activation = non_linear_activation\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(input_dim, 10),\n",
    "            self.non_linear_activation,\n",
    "            nn.Linear(10, output_dim),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048ccc2-4ac8-4eb2-8547-018aacdec9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(N=40):\n",
    "    data,labels=gen_synthetic_data(N=N)\n",
    "    data = data.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    net = NeuralNet().to(DEVICE)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optim = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    EPOCHS = 30\n",
    "    BATCH = 50\n",
    "\n",
    "    ls = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        eloss = 0\n",
    "        for b in range(100):\n",
    "            indexes = torch.randperm(data.shape[0])[:BATCH]\n",
    "            batch = data[indexes]\n",
    "            target = labels[indexes]\n",
    "            \n",
    "            out = net(batch)\n",
    "            loss = loss_fn(out, target)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            eloss += loss.item()\n",
    "\n",
    "        tloss = eloss / data.shape[0]\n",
    "        ls.append(tloss)\n",
    "\n",
    "    return data,labels,net,ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437241db-c805-4b3f-bee3-ae88abb2d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels,net,ls = train(N=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4f980-82c0-4b20-9f93-7ca67cd6fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=None\n",
    "with torch.no_grad():\n",
    "    output = torch.argmax(net(data), dim=-1).cpu().numpy()\n",
    "X = data.cpu().numpy()\n",
    "\n",
    "valid_data = ((torch.rand((500,2)) - 0.5) * 4).to(DEVICE)\n",
    "output_valid=None\n",
    "with torch.no_grad():\n",
    "    output_valid = torch.argmax(net(valid_data), dim=-1).cpu().numpy()\n",
    "\n",
    "fig,arr = plt.subplots(1,4,figsize=(21,5))\n",
    "\n",
    "for a in arr:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n",
    "arr[0].plot(np.arange(len(ls)),ls)\n",
    "arr[0].set_title(\"epoch vs. loss\")\n",
    "\n",
    "for i in range(2):\n",
    "    ind_i = labels.cpu() == i\n",
    "    arr[1].scatter(X[ind_i,0], X[ind_i,1], label=\"positive\" if i > 0 else \"negative\")\n",
    "    arr[1].set_title(\"training data\")\n",
    "\n",
    "fig.legend()\n",
    "\n",
    "for i in range(2):\n",
    "    ind_i = output == i\n",
    "    arr[2].scatter(X[ind_i,0], X[ind_i,1], label=i)\n",
    "    arr[2].set_title(\"output after training\")\n",
    "\n",
    "for i in range(2):\n",
    "    ind_i = output_valid == i\n",
    "    arr[3].scatter(valid_data[ind_i,0].cpu(), valid_data[ind_i,1].cpu(), label=i)\n",
    "    arr[3].set_title(\"validation data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e3d53-be8d-4033-bab9-1b45c13383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_influence_functions as ptif\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfbe3e-7345-466e-82ca-08a4e7bb201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_pt(point):\n",
    "    x1,x2=point\n",
    "    norm = np.square(x1) + np.square(x2)\n",
    "    lab = 1 if norm <= 1 else 0\n",
    "    return (torch.tensor([x1,x2]).to(DEVICE).float(), torch.tensor(lab).to(DEVICE))\n",
    "\n",
    "TESTX = (1.5,1.5)\n",
    "\n",
    "train_data = DataLoader([(x,y) for x,y in zip(data, labels)], batch_size=1, shuffle=False)\n",
    "# test_data = DataLoader([(x,y) for x,y in zip(data[0:1], labels[0:1])], batch_size=1, shuffle=False)\n",
    "test_data = DataLoader([get_test_pt(TESTX)], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5d853-4a4b-4f6a-8f99-f68683ebd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ptif.get_default_config()\n",
    "\n",
    "influence, harmful, helpful, _ = ptif.calc_influence_function.calc_influence_single(\n",
    "    net, train_data, test_data, test_id_num=0, gpu=config['gpu'],\n",
    "    recursion_depth=config['recursion_depth'], r=config['r_averaging'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd05c9f-9f6d-4e08-b452-bf45ef697192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.cpu().numpy()\n",
    "fig, arr = plt.subplots(1,1,figsize=(6,5))\n",
    "scatter = arr.scatter(X[:,0], X[:,1], c=influence, cmap=cm.RdBu_r)\n",
    "arr.scatter(TESTX[0], TESTX[1], c=\"red\")\n",
    "fig.colorbar(scatter)\n",
    "plt.title(\"influence of training data on point (red)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33385a65-1fb3-42f8-9ca0-e81f1ac972d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does out of sample data correlate with abnormally high influence\n",
    "# Can influence predict whether something was in the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ee5f9-bd85-4a13-9441-ad87c7828114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
